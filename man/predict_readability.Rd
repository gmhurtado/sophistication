% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/predict.R
\name{predict_readability}
\alias{predict_readability}
\title{predict readability score from a fitted BT model}
\usage{
predict_readability(object, newdata, reference_top = -2.1763368548,
  reference_bottom = -3.865467, bootstrap_n = 0, verbose = FALSE)
}
\arguments{
\item{object}{a fitted \code{\link[BradleyTerry2]{BTm}} model object}

\item{newdata}{an optional data frame in which to look for texts whose
readability values will be predicted.  This can be a data.frame with the
same covariates as \code{object}, or a corpus or character object.  If
omitted, the fitted values from \code{object} are used.}

\item{reference_top, reference_bottom}{the \eqn{lambda} values of a text
against which each predicted text will be compared for difficulty.  The
default value is the \eqn{lambda} applied to all of
\code{\link{data_corpus_fifthgrade}} (\code{reference_top}), and for the
bottom, the "hardest" text represented by \code{reference_top}.  The
reference values are also used to score the 100 for the rescaled lambda.
The default values come from the snippets we fit to the model taken from
the SOTU corpus.  (See \code{f999866.csv}.)}

\item{bootstrap_n}{number of bootstrap replicates for computing intervals}

\item{verbose}{logical; if \code{TRUE} print status messages}
}
\value{
a data.frame with the rows named to the text names, and the columns
  consisting of: \describe{ \item{\code{lambda}}{estimated lambda for each
  text} \item{\code{prob}}{the probability that the text is easier than the
  reference lambda)} \item{\code{scaled}}{a rescaled lambda on a scale of
  "ease" ranging from 0-100, where 100 is set to the difficulty of the
  reference value (set by default at the fifth-grade reading level).  0 will
  be set at the difficulty level of the most difficult text in the training
  data.} }
}
\description{
Predicts the \eqn{lambda} for a given text in \code{newdata}, from a fitted
Bradley-Terry model object \code{object}.
}
\examples{
\dontrun{
load("analysis_article/output/fitted_BT_model.Rdata")

head(predict_readability(BT_best))
##           lambda       prob   scaled
## 100014 -3.296731 0.24593816 60.51612
## 100028 -3.190470 0.26617180 64.26088
## 100029 -3.719532 0.17607128 45.61617
## 100033 -4.703668 0.07396423 10.93416
## 100034 -3.289739 0.24723716 60.76252
## 100045 -2.780185 0.35346383 78.71976

txts <- c(fifthgrade = paste(texts(data_corpus_fifthgrade), collapse = "  "),
          data_corpus_inaugural[c(1:2, 9:10, 54:58)])
predict_readability(BT_best, newdata = txts)
##                    lambda       prob    scaled
## fifthgrade      -2.168784 0.50188816 100.26616
## 1789-Washington -5.678335 0.02925544 -23.41412
## 1793-Washington -3.607503 0.19291702  49.56418
## 1821-Monroe     -3.666829 0.18384785  47.47347
## 1825-Adams      -4.167703 0.12011246  29.82216
## 2001-Bush       -2.317610 0.46474035  95.02139
## 2005-Bush       -2.652254 0.38321669  83.22817
## 2009-Obama      -2.594972 0.39684336  85.24685
## 2013-Obama      -2.779760 0.35356091  78.73473
## 2017-Trump      -2.370844 0.45152595  93.14536

names(txts) <- gsub("ington", "", names(txts))
pr <- predict_readability(BT_best, newdata = txts[c(1:3, 9:10)], bootstrap_n = 100)
format(pr, digits = 4)
##            lambda    prob scaled lambda_lo lambda_hi  prob_lo prob_hi scaled_lo scaled_hi
## fifthgrade -2.172 0.50105 100.15    -2.210    -2.135 0.491591 0.51032     98.81   101.455
## 1789-Wash  -5.676 0.02931 -23.35    -6.917    -4.870 0.008664 0.06336    -67.06     5.076
## 1793-Wash  -3.560 0.20036  51.22    -4.524    -2.609 0.087218 0.39358     17.25    84.765
## 2013-Obama -2.791 0.35107  78.35    -2.914    -2.645 0.323485 0.38483     74.00    83.469
## 2017-Trump -2.381 0.44904  92.79    -2.511    -2.213 0.417178 0.49080     88.22    98.704

predict_readability(BT_best, newdata = "The cat in the hat ate green eggs and ham.")
##      lambda      prob   scaled
## 1 -1.125721 0.7408932 137.0248

}
}
