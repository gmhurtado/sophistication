\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Methods: Crowdsourcing Complexity}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Preparing the Snippets: Gold Standards and Crowdflower}{1}{subsection.1.1}}
\citation{Benoitetal2016}
\citation{berinsky2014separating}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Incorporating Familiarity: Google n-grams and parts of speech}{3}{subsection.1.2}}
\citation{traenklebailer:1984}
\citation{ColemanLiau75}
\citation{BradleyTerry52}
\citation{McCullaghNelder89}
\citation{TurnerFirth12}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Bradley-Terry Regression Analysis}{5}{subsection.1.3}}
\newlabel{Eqn:BT}{{1}{5}{Bradley-Terry Regression Analysis}{equation.1.1}{}}
\newlabel{Eqn:structured}{{2}{5}{Bradley-Terry Regression Analysis}{equation.1.2}{}}
\citation{Firth93}
\citation{Breiman2001}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Variable Selection via Machine Learning}{6}{subsubsection.1.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}A ``Bag-of-Snippets'' Approach}{7}{subsection.1.4}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Model performance of the standard measures. The overall fit of the Bradley-Terry model using the scores for a given measure is reported in two ways: the Akaike information criterion (AIC) and the Proportion of contest results correctly predicted (where a correctly predicted contest is one in which there is $>0.5$ probability that the actual winner would win).}}{8}{table.1}}
\newlabel{model_fit}{{1}{8}{Model performance of the standard measures. The overall fit of the Bradley-Terry model using the scores for a given measure is reported in two ways: the Akaike information criterion (AIC) and the Proportion of contest results correctly predicted (where a correctly predicted contest is one in which there is $>0.5$ probability that the actual winner would win)}{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Results}{8}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Comparing the Standard Measures}{8}{subsection.2.1}}
\citation{Firth93}
\citation{Flesch48}
\citation{Flesch48}
\citation{Flesch48}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Augmented Bradley Terry Approach}{9}{subsection.2.2}}
\citation{Flesch48}
\@writefile{toc}{\contentsline {section}{\numberline {3}Applications: snippets, \textit  {State of the Union} and \textit  {Hansard}}{11}{section.3}}
\newlabel{Eqn:predprob}{{3}{11}{Applications: snippets, \textit {State of the Union} and \textit {Hansard}}{equation.3.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Model comparison, post feature-selection. Note that the last column represents our `optimal' model. `PCP' is proportion (of contests) correctly predicted by the model. }}{12}{table.2}}
\newlabel{Table:ModelCompare}{{2}{12}{Model comparison, post feature-selection. Note that the last column represents our `optimal' model. `PCP' is proportion (of contests) correctly predicted by the model}{table.2}{}}
\citation{Flesch48}
\citation{Flesch48}
\citation{LoweBenoit13}
\citation{Flesch48}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Examples of covariates from two snippets in the data. }}{13}{table.3}}
\newlabel{Table:snippetcovar}{{3}{13}{Examples of covariates from two snippets in the data}{table.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}The Original Snippet Dataset}{14}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Comparing the `linear' version of our measure to FRE of the snippets. Correlation is generally high, especially for the theoretical range of the FRE (inner box). }}{15}{figure.1}}
\newlabel{Figure:compare linear}{{1}{15}{Comparing the `linear' version of our measure to FRE of the snippets. Correlation is generally high, especially for the theoretical range of the FRE (inner box)}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Reanalyzing the \textit  {State of the Union} addresses}{15}{subsection.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  }}{16}{figure.2}}
\newlabel{Figure:measure fifth}{{2}{16}{}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comparing the `linear', continuous version of our model based estimates (points plus 95\% confidence intervals, denoted MBE) to FRE (smooth lines, with outer edges representing 95\% confidence intervals) of the State of Union addresses. Note that the time series are initially similar, but depart from one another around the year 1910. }}{17}{figure.3}}
\newlabel{Figure:compare linear SOTU}{{3}{17}{Comparing the `linear', continuous version of our model based estimates (points plus 95\% confidence intervals, denoted MBE) to FRE (smooth lines, with outer edges representing 95\% confidence intervals) of the State of Union addresses. Note that the time series are initially similar, but depart from one another around the year 1910}{figure.3}{}}
\citation{LiawWiener02}
\newlabel{AppRFVI}{{A}{18}{Random Forest Variable Importance Plots}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Random Forest Variable Importance Plots }{18}{appendix.A}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Variable Importance Plots for (unstructured) readability estimates. Note that points further to the right imply more `important' variables. Top panel is for bias-reduced estimates; bottom panel is for non-bias reduced estimates. }}{19}{figure.4}}
\newlabel{Figure:VI}{{4}{19}{Variable Importance Plots for (unstructured) readability estimates. Note that points further to the right imply more `important' variables. Top panel is for bias-reduced estimates; bottom panel is for non-bias reduced estimates}{figure.4}{}}
\bibstyle{apsr}
\bibdata{BMS_readability}
\bibcite{Benoitetal2016}{{1}{2016}{{Benoit et~al.}}{{Benoit, Conway, Lauderdale, Laver and\ Mikhaylov}}}
\bibcite{berinsky2014separating}{{2}{2014}{{Berinsky, Margolis and\ Sances}}{{Berinsky, Margolis and\ Sances}}}
\bibcite{BradleyTerry52}{{3}{1952}{{Bradley and\ Terry}}{{}}}
\bibcite{Breiman2001}{{4}{2001}{{Breiman}}{{}}}
\bibcite{ColemanLiau75}{{5}{1975}{{Coleman and\ Liau}}{{}}}
\bibcite{Firth93}{{6}{1993}{{Firth}}{{}}}
\bibcite{Flesch48}{{7}{1948}{{Flesch}}{{}}}
\bibcite{LiawWiener02}{{8}{2002}{{Liaw and\ Wiener}}{{}}}
\bibcite{LoweBenoit13}{{9}{2013}{{Lowe and\ Benoit}}{{}}}
\bibcite{McCullaghNelder89}{{10}{1989}{{McCullagh and\ Nelder}}{{}}}
\bibcite{traenklebailer:1984}{{11}{1984}{{Tr{\"a}nkle and\ Bailer}}{{}}}
\bibcite{TurnerFirth12}{{12}{2012}{{Turner and\ Firth}}{{}}}
